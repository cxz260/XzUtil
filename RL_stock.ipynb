{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMt2hrL8mLkSSuf1ZBQrbu2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cxz260/XzUtil/blob/main/RL_stock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy pandas yfinance gym"
      ],
      "metadata": {
        "id": "jCl9sHftRnzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class StockEnv(gym.Env):\n",
        "    def __init__(self, stock_data, window_size=5, initial_balance=10000):\n",
        "        super(StockEnv, self).__init__()\n",
        "        self.stock_data = stock_data\n",
        "        self.window_size = window_size\n",
        "        self.initial_balance = initial_balance\n",
        "\n",
        "        self.action_space = gym.spaces.Discrete(3)  # Buy, Hold, Sell\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=np.inf, shape=(window_size,))\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def step(self, action):\n",
        "        self.current_step += 1\n",
        "\n",
        "        if self.current_step >= len(self.stock_data) - 1:\n",
        "            done = True\n",
        "        else:\n",
        "            done = False\n",
        "\n",
        "        prev_balance = self.balance\n",
        "        prev_stock_value = self.stock_data[self.current_step - 1] * self.stock_count\n",
        "\n",
        "        if action == 0:  # Buy\n",
        "            self.stock_count += self.balance // self.stock_data[self.current_step]\n",
        "            self.balance %= self.stock_data[self.current_step]\n",
        "        elif action == 2:  # Sell\n",
        "            self.balance += self.stock_data[self.current_step] * self.stock_count\n",
        "            self.stock_count = 0\n",
        "\n",
        "        current_stock_value = self.stock_data[self.current_step] * self.stock_count\n",
        "        reward = (self.balance + current_stock_value) - (prev_balance + prev_stock_value)\n",
        "\n",
        "        return self._next_observation(), reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.balance = self.initial_balance\n",
        "        self.stock_count = 0\n",
        "        self.current_step = self.window_size\n",
        "        return self._next_observation()\n",
        "\n",
        "    def _next_observation(self):\n",
        "        return self.stock_data[self.current_step - self.window_size : self.current_step]\n",
        "\n",
        "    def render(self):\n",
        "        print(f\"Step: {self.current_step}, Balance: {self.balance}, Stock count: {self.stock_count}\")\n"
      ],
      "metadata": {
        "id": "5j6xJgRZQdU9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "from collections import deque\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_size, action_size, hidden_size=64, lr=0.001, gamma=0.99, epsilon=1.0, epsilon_decay=0.995, epsilon_min=0.01, memory_size=10000, batch_size=32, device=\"cpu\"):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lr = lr\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.memory_size = memory_size\n",
        "        self.batch_size = batch_size\n",
        "        self.device = device\n",
        "\n",
        "        self.memory = deque(maxlen=self.memory_size)\n",
        "        self.model = self._build_model().to(self.device)\n",
        "        self.target_model = self._build_model().to(self.device)\n",
        "        self.update_target_model()\n",
        "\n",
        "    def _build_model(self):\n",
        "        model = nn.Sequential(\n",
        "            nn.Linear(self.state_size, self.hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.hidden_size, self.hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.hidden_size, self.action_size)\n",
        "            )\n",
        "        return model\n",
        "\n",
        "    def update_target_model(self):\n",
        "      self.target_model.load_state_dict(self.model.state_dict())\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "      self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        state_tensor = torch.FloatTensor(state).to(self.device)\n",
        "        q_values = self.model(state_tensor)\n",
        "        return np.argmax(q_values.detach().cpu().numpy())\n",
        "\n",
        "    def replay(self):\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return\n",
        "\n",
        "        minibatch = random.sample(self.memory, self.batch_size)\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            target = reward\n",
        "            if not done:\n",
        "                next_state_tensor = torch.FloatTensor(next_state).to(self.device)\n",
        "                target = reward + self.gamma * np.amax(self.target_model(next_state_tensor).detach().cpu().numpy())\n",
        "\n",
        "            state_tensor = torch.FloatTensor(state).to(self.device)\n",
        "            target_f = self.model(state_tensor)\n",
        "            target_f[action] = target\n",
        "            target_f = target_f.to(self.device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = self.model(state_tensor)\n",
        "            loss = criterion(output, target_f)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n"
      ],
      "metadata": {
        "id": "hsagN9SKQzAt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "\n",
        "# Download stock data\n",
        "ticker = \"AAPL\"\n",
        "start_date = \"2020-01-01\"\n",
        "end_date = \"2021-01-01\"\n",
        "stock_data = yf.download(ticker, start=start_date, end=end_date)[\"Adj Close\"].values\n",
        "\n",
        "# Create the environment\n",
        "window_size = 5\n",
        "env = StockEnv(stock_data, window_size=window_size)\n",
        "\n",
        "# Create the agent\n",
        "state_size = window_size\n",
        "action_size = env.action_space.n\n",
        "agent = DQNAgent(state_size, action_size, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Train the agent\n",
        "episodes = 200\n",
        "for e in range(episodes):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = agent.act(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        agent.remember(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        agent.replay()\n",
        "\n",
        "    agent.update_target_model()\n",
        "    print(f\"Episode: {e + 1}/{episodes}, Epsilon: {agent.epsilon:.2f}\")\n",
        "\n",
        "print(\"Training completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVLeCD_jcoJn",
        "outputId": "b773d858-4402-4db3-9921-f205acc915a7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "Episode: 1/200, Epsilon: 0.34\n",
            "Episode: 2/200, Epsilon: 0.10\n",
            "Episode: 3/200, Epsilon: 0.03\n",
            "Episode: 4/200, Epsilon: 0.01\n",
            "Episode: 5/200, Epsilon: 0.01\n",
            "Episode: 6/200, Epsilon: 0.01\n",
            "Episode: 7/200, Epsilon: 0.01\n",
            "Episode: 8/200, Epsilon: 0.01\n",
            "Episode: 9/200, Epsilon: 0.01\n",
            "Episode: 10/200, Epsilon: 0.01\n",
            "Episode: 11/200, Epsilon: 0.01\n",
            "Episode: 12/200, Epsilon: 0.01\n",
            "Episode: 13/200, Epsilon: 0.01\n",
            "Episode: 14/200, Epsilon: 0.01\n",
            "Episode: 15/200, Epsilon: 0.01\n",
            "Episode: 16/200, Epsilon: 0.01\n",
            "Episode: 17/200, Epsilon: 0.01\n",
            "Episode: 18/200, Epsilon: 0.01\n",
            "Episode: 19/200, Epsilon: 0.01\n",
            "Episode: 20/200, Epsilon: 0.01\n",
            "Episode: 21/200, Epsilon: 0.01\n",
            "Episode: 22/200, Epsilon: 0.01\n",
            "Episode: 23/200, Epsilon: 0.01\n",
            "Episode: 24/200, Epsilon: 0.01\n",
            "Episode: 25/200, Epsilon: 0.01\n",
            "Episode: 26/200, Epsilon: 0.01\n",
            "Episode: 27/200, Epsilon: 0.01\n",
            "Episode: 28/200, Epsilon: 0.01\n",
            "Episode: 29/200, Epsilon: 0.01\n",
            "Episode: 30/200, Epsilon: 0.01\n",
            "Episode: 31/200, Epsilon: 0.01\n",
            "Episode: 32/200, Epsilon: 0.01\n",
            "Episode: 33/200, Epsilon: 0.01\n",
            "Episode: 34/200, Epsilon: 0.01\n",
            "Episode: 35/200, Epsilon: 0.01\n",
            "Episode: 36/200, Epsilon: 0.01\n",
            "Episode: 37/200, Epsilon: 0.01\n",
            "Episode: 38/200, Epsilon: 0.01\n",
            "Episode: 39/200, Epsilon: 0.01\n",
            "Episode: 40/200, Epsilon: 0.01\n",
            "Episode: 41/200, Epsilon: 0.01\n",
            "Episode: 42/200, Epsilon: 0.01\n",
            "Episode: 43/200, Epsilon: 0.01\n",
            "Episode: 44/200, Epsilon: 0.01\n",
            "Episode: 45/200, Epsilon: 0.01\n",
            "Episode: 46/200, Epsilon: 0.01\n",
            "Episode: 47/200, Epsilon: 0.01\n",
            "Episode: 48/200, Epsilon: 0.01\n",
            "Episode: 49/200, Epsilon: 0.01\n",
            "Episode: 50/200, Epsilon: 0.01\n",
            "Episode: 51/200, Epsilon: 0.01\n",
            "Episode: 52/200, Epsilon: 0.01\n",
            "Episode: 53/200, Epsilon: 0.01\n",
            "Episode: 54/200, Epsilon: 0.01\n",
            "Episode: 55/200, Epsilon: 0.01\n",
            "Episode: 56/200, Epsilon: 0.01\n",
            "Episode: 57/200, Epsilon: 0.01\n",
            "Episode: 58/200, Epsilon: 0.01\n",
            "Episode: 59/200, Epsilon: 0.01\n",
            "Episode: 60/200, Epsilon: 0.01\n",
            "Episode: 61/200, Epsilon: 0.01\n",
            "Episode: 62/200, Epsilon: 0.01\n",
            "Episode: 63/200, Epsilon: 0.01\n",
            "Episode: 64/200, Epsilon: 0.01\n",
            "Episode: 65/200, Epsilon: 0.01\n",
            "Episode: 66/200, Epsilon: 0.01\n",
            "Episode: 67/200, Epsilon: 0.01\n",
            "Episode: 68/200, Epsilon: 0.01\n",
            "Episode: 69/200, Epsilon: 0.01\n",
            "Episode: 70/200, Epsilon: 0.01\n",
            "Episode: 71/200, Epsilon: 0.01\n",
            "Episode: 72/200, Epsilon: 0.01\n",
            "Episode: 73/200, Epsilon: 0.01\n",
            "Episode: 74/200, Epsilon: 0.01\n",
            "Episode: 75/200, Epsilon: 0.01\n",
            "Episode: 76/200, Epsilon: 0.01\n",
            "Episode: 77/200, Epsilon: 0.01\n",
            "Episode: 78/200, Epsilon: 0.01\n",
            "Episode: 79/200, Epsilon: 0.01\n",
            "Episode: 80/200, Epsilon: 0.01\n",
            "Episode: 81/200, Epsilon: 0.01\n",
            "Episode: 82/200, Epsilon: 0.01\n",
            "Episode: 83/200, Epsilon: 0.01\n",
            "Episode: 84/200, Epsilon: 0.01\n",
            "Episode: 85/200, Epsilon: 0.01\n",
            "Episode: 86/200, Epsilon: 0.01\n",
            "Episode: 87/200, Epsilon: 0.01\n",
            "Episode: 88/200, Epsilon: 0.01\n",
            "Episode: 89/200, Epsilon: 0.01\n",
            "Episode: 90/200, Epsilon: 0.01\n",
            "Episode: 91/200, Epsilon: 0.01\n",
            "Episode: 92/200, Epsilon: 0.01\n",
            "Episode: 93/200, Epsilon: 0.01\n",
            "Episode: 94/200, Epsilon: 0.01\n",
            "Episode: 95/200, Epsilon: 0.01\n",
            "Episode: 96/200, Epsilon: 0.01\n",
            "Episode: 97/200, Epsilon: 0.01\n",
            "Episode: 98/200, Epsilon: 0.01\n",
            "Episode: 99/200, Epsilon: 0.01\n",
            "Episode: 100/200, Epsilon: 0.01\n",
            "Episode: 101/200, Epsilon: 0.01\n",
            "Episode: 102/200, Epsilon: 0.01\n",
            "Episode: 103/200, Epsilon: 0.01\n",
            "Episode: 104/200, Epsilon: 0.01\n",
            "Episode: 105/200, Epsilon: 0.01\n",
            "Episode: 106/200, Epsilon: 0.01\n",
            "Episode: 107/200, Epsilon: 0.01\n",
            "Episode: 108/200, Epsilon: 0.01\n",
            "Episode: 109/200, Epsilon: 0.01\n",
            "Episode: 110/200, Epsilon: 0.01\n",
            "Episode: 111/200, Epsilon: 0.01\n",
            "Episode: 112/200, Epsilon: 0.01\n",
            "Episode: 113/200, Epsilon: 0.01\n",
            "Episode: 114/200, Epsilon: 0.01\n",
            "Episode: 115/200, Epsilon: 0.01\n",
            "Episode: 116/200, Epsilon: 0.01\n",
            "Episode: 117/200, Epsilon: 0.01\n",
            "Episode: 118/200, Epsilon: 0.01\n",
            "Episode: 119/200, Epsilon: 0.01\n",
            "Episode: 120/200, Epsilon: 0.01\n",
            "Episode: 121/200, Epsilon: 0.01\n",
            "Episode: 122/200, Epsilon: 0.01\n",
            "Episode: 123/200, Epsilon: 0.01\n",
            "Episode: 124/200, Epsilon: 0.01\n",
            "Episode: 125/200, Epsilon: 0.01\n",
            "Episode: 126/200, Epsilon: 0.01\n",
            "Episode: 127/200, Epsilon: 0.01\n",
            "Episode: 128/200, Epsilon: 0.01\n",
            "Episode: 129/200, Epsilon: 0.01\n",
            "Episode: 130/200, Epsilon: 0.01\n",
            "Episode: 131/200, Epsilon: 0.01\n",
            "Episode: 132/200, Epsilon: 0.01\n",
            "Episode: 133/200, Epsilon: 0.01\n",
            "Episode: 134/200, Epsilon: 0.01\n",
            "Episode: 135/200, Epsilon: 0.01\n",
            "Episode: 136/200, Epsilon: 0.01\n",
            "Episode: 137/200, Epsilon: 0.01\n",
            "Episode: 138/200, Epsilon: 0.01\n",
            "Episode: 139/200, Epsilon: 0.01\n",
            "Episode: 140/200, Epsilon: 0.01\n",
            "Episode: 141/200, Epsilon: 0.01\n",
            "Episode: 142/200, Epsilon: 0.01\n",
            "Episode: 143/200, Epsilon: 0.01\n",
            "Episode: 144/200, Epsilon: 0.01\n",
            "Episode: 145/200, Epsilon: 0.01\n",
            "Episode: 146/200, Epsilon: 0.01\n",
            "Episode: 147/200, Epsilon: 0.01\n",
            "Episode: 148/200, Epsilon: 0.01\n",
            "Episode: 149/200, Epsilon: 0.01\n",
            "Episode: 150/200, Epsilon: 0.01\n",
            "Episode: 151/200, Epsilon: 0.01\n",
            "Episode: 152/200, Epsilon: 0.01\n",
            "Episode: 153/200, Epsilon: 0.01\n",
            "Episode: 154/200, Epsilon: 0.01\n",
            "Episode: 155/200, Epsilon: 0.01\n",
            "Episode: 156/200, Epsilon: 0.01\n",
            "Episode: 157/200, Epsilon: 0.01\n",
            "Episode: 158/200, Epsilon: 0.01\n",
            "Episode: 159/200, Epsilon: 0.01\n",
            "Episode: 160/200, Epsilon: 0.01\n",
            "Episode: 161/200, Epsilon: 0.01\n",
            "Episode: 162/200, Epsilon: 0.01\n",
            "Episode: 163/200, Epsilon: 0.01\n",
            "Episode: 164/200, Epsilon: 0.01\n",
            "Episode: 165/200, Epsilon: 0.01\n",
            "Episode: 166/200, Epsilon: 0.01\n",
            "Episode: 167/200, Epsilon: 0.01\n",
            "Episode: 168/200, Epsilon: 0.01\n",
            "Episode: 169/200, Epsilon: 0.01\n",
            "Episode: 170/200, Epsilon: 0.01\n",
            "Episode: 171/200, Epsilon: 0.01\n",
            "Episode: 172/200, Epsilon: 0.01\n",
            "Episode: 173/200, Epsilon: 0.01\n",
            "Episode: 174/200, Epsilon: 0.01\n",
            "Episode: 175/200, Epsilon: 0.01\n",
            "Episode: 176/200, Epsilon: 0.01\n",
            "Episode: 177/200, Epsilon: 0.01\n",
            "Episode: 178/200, Epsilon: 0.01\n",
            "Episode: 179/200, Epsilon: 0.01\n",
            "Episode: 180/200, Epsilon: 0.01\n",
            "Episode: 181/200, Epsilon: 0.01\n",
            "Episode: 182/200, Epsilon: 0.01\n",
            "Episode: 183/200, Epsilon: 0.01\n",
            "Episode: 184/200, Epsilon: 0.01\n",
            "Episode: 185/200, Epsilon: 0.01\n",
            "Episode: 186/200, Epsilon: 0.01\n",
            "Episode: 187/200, Epsilon: 0.01\n",
            "Episode: 188/200, Epsilon: 0.01\n",
            "Episode: 189/200, Epsilon: 0.01\n",
            "Episode: 190/200, Epsilon: 0.01\n",
            "Episode: 191/200, Epsilon: 0.01\n",
            "Episode: 192/200, Epsilon: 0.01\n",
            "Episode: 193/200, Epsilon: 0.01\n",
            "Episode: 194/200, Epsilon: 0.01\n",
            "Episode: 195/200, Epsilon: 0.01\n",
            "Episode: 196/200, Epsilon: 0.01\n",
            "Episode: 197/200, Epsilon: 0.01\n",
            "Episode: 198/200, Epsilon: 0.01\n",
            "Episode: 199/200, Epsilon: 0.01\n",
            "Episode: 200/200, Epsilon: 0.01\n",
            "Training completed.\n"
          ]
        }
      ]
    }
  ]
}