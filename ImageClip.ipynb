{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpK9Y6sZi5tI/ddq/++XGi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cxz260/XzUtil/blob/main/ImageClip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "id": "E2GaxYJrpJAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load the pre-trained ResNet50 model with ImageNet weights\n",
        "model = ResNet50(weights='imagenet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC5po5-fpZ6f",
        "outputId": "914f79f2-5921-473f-f5d4-a6cf518f765d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102967424/102967424 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/Mytree.jpg\"\n",
        "\n",
        "# Load and preprocess your image\n",
        "img = image.load_img(image_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = preprocess_input(img_array)\n",
        "\n",
        "# Make a prediction\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "# Decode the prediction\n",
        "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
        "\n",
        "print(\"Predicted classifications:\")\n",
        "for i, (imagenet_id, label, prob) in enumerate(decoded_predictions):\n",
        "    print(f\"{i+1}. {label}: {prob * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0O7MdjKpuwW",
        "outputId": "b0992aab-5cd2-4ed2-c4b5-91e3348e1038"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "35363/35363 [==============================] - 0s 0us/step\n",
            "Predicted classifications:\n",
            "1. pole: 39.38%\n",
            "2. walking_stick: 24.82%\n",
            "3. cabbage_butterfly: 13.59%\n",
            "4. picket_fence: 2.78%\n",
            "5. greenhouse: 2.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Using CLIP model\n"
      ],
      "metadata": {
        "id": "fGAJ_JeMw7s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision ftfy"
      ],
      "metadata": {
        "id": "ftkC2blctKJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf CLIP\n",
        "!git clone https://github.com/openai/CLIP.git\n",
        "!pip install -e ./CLIP"
      ],
      "metadata": {
        "id": "tNCPrUaEtrjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/CLIP')"
      ],
      "metadata": {
        "id": "HDff_8_IwdEr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "from ftfy import fix_text\n",
        "from torch.nn.functional import softmax\n",
        "import clip\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muJHCWoKtDR4",
        "outputId": "64caabee-8f0c-419a-cf27-02e9d06312d1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 338M/338M [00:07<00:00, 44.6MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/Mytree.jpg\"\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "image_input = preprocess(image).unsqueeze(0).to(device)\n",
        "tree_species = [\n",
        "    \"acer palmatum\", \"silver birch\", \"scots pine\", \"norway spruce\", \"english oak\",\n",
        "    \"weeping willow\", \"american elm\", \"sugar maple\", \"colorado blue spruce\",\n",
        "    \"black walnut\", \"white oak\", \"douglas fir\", \"giant sequoia\", \"quaking aspen\"\n",
        "]\n",
        "\n",
        "text_input = clip.tokenize([fix_text(species) for species in tree_species]).to(device)\n",
        "with torch.no_grad():\n",
        "    image_features = model.encode_image(image_input)\n",
        "    text_features = model.encode_text(text_input)\n",
        "    logits = image_features @ text_features.T\n",
        "    probs = softmax(logits, dim=-1)\n",
        "\n",
        "probs = probs.cpu().numpy().flatten()\n",
        "predicted_species = tree_species[probs.argmax()]\n",
        "print(f\"Predicted tree species: {predicted_species} (probabilities: {probs})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q3ojAxXwndU",
        "outputId": "b474933b-b9df-42a2-a4a0-024966945294"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted tree species: white oak (probabilities: [1.04222854e-03 3.00771004e-04 1.07295895e-02 8.89795925e-03\n",
            " 1.60680208e-02 1.09218262e-01 2.42957354e-01 1.95050508e-01\n",
            " 4.96348366e-04 6.09508455e-02 3.38462621e-01 1.17816767e-02\n",
            " 2.16734243e-05 4.02205391e-03])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hgWweo2As3lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pGC-KNpts3Rw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}